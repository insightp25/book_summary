# 동적 계획법, 그리디 알고리즘

# 주먹구구식 배낭 문제 풀기

## 동적 계획법(dynamic programming, DP)

- 특별한 속성을 가진 복잡한 문제를 푸는 방법
- 복잡한 문제를 그보다 단순한 하위 문제로 나눠서 품
  - 재귀적
  - 가장 단순한 문제 + 1은 그 다음으로 단순한 문제
  - 이걸 반복하면 원래의 복잡한 문제까지 해결
- 당연히 모든 문제를 이렇게 풀 수는 없음
  - 특별한 속성이 필요


## 복잡한 문제의 예: 배낭(knapsack) 문제

- 크기와 가격이 다른 여러 물품이 있음
- 값어치가 최대가 되도록 물건 넣기
- 당연히 배낭에는 크기 제한이 있음
- 판정 버전은 약한 NP-완전 문제
  - "최소 어떤 값어치 V만큼 넣을 수 있는가?"
  - 의사 다항식 시간 안에 풀 수 있음

## 배낭 문제가 어려운 이유

- 주먹구구식으로 풀 경우 모든 경우의 수를 따져봐야 함
- 배낭에 들어가면서도 값어치가 최고인 조합이 답
- 물품 하나가 추가될 때마다 경우의 수가 2배씩 뜀
- 시간 복잡도: O(2^n)

동적 계획법을 사용하면 시간을 크게 줄일 수 있다

(하지만 좀 더 쉬운 문제부터 보자)




<br>

# 메모이제이션

## 피보나치 수(예전에 본 방식)

- 시간 복잡도: O(2^n)
  - 너무 느림
  - 쓸데없는 중복 계산 때문

```java
public static int fibonacciRecursive(int number) {
	if (number <= 1) {
		return number;
	}

	return fibonacciRecursive(number - 2) + fibonacciRecursive(number - 1);
}
```

## 메모이제이션(memoization)

- 계산 결과를 캐시에 저장해 둔 뒤, 나중에 재사용하는 기법
  - 처음 계산할 때 그 결과를 캐시에 저장
  - 나중에 동일한 계산을 다시 하는 대신 저장해둔 값을 가져다 씀
  - 값비싼 계산(예: 깊은 재귀 호출)에 적합
  - 최적화 기법 중 하나, 캐싱 기법 중 하나
- 보통 함수가 매개변수에 따라 반환하는 값을 캐싱하는 것을 지칭
- 컴퓨터 프로그래밍에서만 사용하는 용어

피보나치 계산 결과를 캐싱하기에 적합한 자료구조는? 배열류!







<br>

# 메모이제이션을 사용한 피보나치 함수

## 메모이제이션을 사용한 피보나치 함수

```java
public static int fibonacciRecursive(int number, int[] cache) {
	if (number <= 1) {
		return number;
	}

	if (cache[number] != 0) {
		return cache[number];
	}

	int ret = fibonacciRecursive(number - 2, cache) + fibonacciRecursive(number - 1, cache);

	cache[number] = ret;

	return ret;
}
```

"이미 풀었던 하위 문제" -> 기억하기!



## 동적 계획법과 메모이제이션
- 전혀 다른 개념
  - 메모이제이션: 실행된 결과를 기억해뒀다가 재사용하는 최적화 기법
  - 동적 계획법: 복잡한 문제를 하위 문제로 쪼개서 재귀적으로 푸는 방법
- 하지만 동적 계획법 = 메모이제이션이라 흔히 오해함
  - 동적 계획법에서 툭하면 사용하는 기법이 메모이제이션이기 때문
  - 하지만 메모이제이션이 동적 계획법에 필수가 아님
  - 동적 계획법의 성능을 향상할 뿐!
- 다른 곳에서도 메모이제이션을 사용함

이전의 피보나치 재귀함수는 위에서 아래로 문제 해결(top-down)


## top-down 동적 계획법

(메모이제이션 동적 계획법이라고도 한다)

- 최종적으로 풀려고 하는 복잡한 문제(루트)에서 시작
- 필요에 따라 재귀적으로 하위 문제를 풂
  - 두 번 이상 평가하는 문제는 캐시 덕분에 계산 생략
  - 하위 문제를 평가하는 ***최적의 순서***를 알 필요 없음 -> !!
- 기존의 재귀 함수를 크게 변경하지 않아도 됨
  - 그냥 캐시 로직을 추가할 뿐!
  - 생각해내기도 구현하기도 편함




<br>

# 타뷸레이션

## 최적의 피보나치 평가 순서를 찾아서

- fib(6)을 구하려면 fib(5)와 fib(4)가 필요
- fib(5)를 구하려면 fib(4)와 fib(3)이 필요
- fib(4)를 구하려면 fib(3)과 fib(2)가 필요
- fib(3)을 구하려면 fib(2)와 fib(1)이 필요
- fib(2)를 구하려면 fib(1)과 fib(0)이 필요
- fib(1)은 1
- fib(0)은 0

패턴이 있나?

1. 아래 값이 있으면 윗 값을 계산 가능!
2. 윗 값은 바로 아래의 값에 의존!


## 아래서 위로 푸는 피보나치 수열

```java
public static int fibonacci (int number) {
	// 편의상 배열
	int cache[] = new int[number + 1];
	cache [0] = 0;
	cache [1] = 1;

	for (int i = 2; i <= number; ++i) {
		cache[i] = cache[i - 2] + cache[i - 1];
	｝

	return cache[number];
}
```

이런 방식(아래에서 위로 해결)을 타뷸레이션(tabulation 또는 bottom-up 방식)이라고 한다.

## bottom-up 동적 계획법

- 가장 작은 문제(리프)부터 시작
- 순서대로 그보다 하나 더 큰 문제를 풀어나감
  - 필요하지 않은 하위 문제도 평가할 수 있음
  - 문제를 잘 분석해서 ***최적의 순서***를 찾아야 함
- top-down 방식보다 보통 더 빠름
  - CPU 캐시에 좀 더 친화적(작은 것부터 큰 것까지 순서대로 빌드해나가면서 조금 전에 계산했던 값을 곧바로 읽어오기 때문)
  - 재귀 함수 호출을 피할 수 있음
  - 모든 하위 문제를 평가할 필요가 없는 경우에는 예외
    - eg. 하위문제가 500개 -> top-down은 두 번만 계산, bottom-up은 500번 모두 계산 필요할 수도

## 속도 향상은 공짜가 아님

- 메모이제이션/타뷸레이션은 속도 향상을 위한 기법
- 그걸 위해 메모리 더 사용
- 역시 시간 복잡도와 공간 복잡도가 반비례인 관계가 꽤 있다






<br>

# 동적 계획법으로 푸는 배낭 문제


## 동적 계획법으로 푸는 배낭 문제

- 작은 배낭부터 최적의 해법을 찾아나감
  - 예: 1칸 배낭 > 2칸 배낭 > 3칸 배낭 > ...
- 작은 배낭의 해법에 기초하여 원래 문제의 최적의 해법을 찾음
  - 예: 1칸 배낭의 최적 해법 + 3칸 배낭의 최적 해법 = 4칸 배낭의 최적 해법

## 우선 그리드(grid)를 만든다

- 모든 동적 계획법 알고리즘은 그리드로 시작
- 각 cell 마다 간단한 결정(훔침 vs 안훔침)을 내림
- 각 cell의 값은 훔칠 수 있는 최댓값

## 그리드에서 각 아이템별로 최대값 계산

## 새로운 아이템 추가시

- 새로운 물품을 추가해도 매우 간단
  - 고려할 상황이 2배로 늘어나지 않음 -> 0(2^N) X
  - 그냥 배낭 칸수만큼만 한 번만 더 훑으면 끝! -> O(NS)
- 바로 전 줄의 값과 비교해서 큰 것을 취하면 끝







<br>

# 동적 계획법을 적용할 수 있는 문제

## 동적 계획법으로 푼 배낭 문제 공식

- 여태까지 본 걸 공식으로 만들면...
- `cell[i][j]`의 값은 다음 중 큰 값
  - 현재 물품 추가 전의 최댓값(`ce11[i - 1][j]`)
  - 현재 물품의 값
    + 남은 공간에 넣을 수 있던 최댓값(`cell[i - 1][j - item.space]`)


## 배낭 문제 + 메모이제이션

- 방금 본 방법은 타뷸레이션을 이용
- 재귀 + 메모이제이션으로도 풀 수 있음


## 동적 계획법을 적용할 수 있는 문제의 특징

1. 최적 부분 구조(optimal substructure)
  - 하위 문제의 최적 해법으로부터 큰 문제의 최적 해법을 구할 수 있음
  - 동적 계획법과 그리디 알고리듬의 유용성 판단에 사용
  - 강화 학습에서 흔히 등장하는 벨만 방정식도 이에 기초
  - 예: 최단 경로 찾기

2. 하위 문제의 반복
  - 똑같은 평가를 반복해야 함(다다익선!)
  - 하위 문제의 크기가 작아야 함
  - 예: 피보나치 수열

분할 정복과 비슷하지 않나? -> 비슷하지만 분명 다른 점이 있다.

## 분할 정복 vs 동적 계획법

|분할 정복|동적 계획법|
|---|---|
|- 큰 문제를 하위 문제로 나눔|- 큰 문제를 하위 문제로 나눔|
|- 하위 문제의 최적의 해법을 합침|- 하위 문제의 해법을 합침|
|- ***반복되지 않는*** 하위 문제|- ***반복되는*** 하위 문제|



## 병합 정렬이 동적 계획법이 아닌 이유

- 대표적인 분할 정복 알고리듬
- 재귀적으로 하위 배열을 정렬한 뒤 병합함
- 각 하위 배열은 다름(반복되지않음!)
- 따라서 동적 계획법이 아님
- 퀵 정렬도 마찬가지






<br>

# 동적 계획법으로 문제를 푸는 과정

## 동적 계획법으로 문제를 푸는 과정

(처음부터 '동적 계획법을 적용해 문제를 풀겠다'하고 마음 먹고 푸는 경우는 잘 없는 것 같고, 풀다가 그렇게 되는 경우가 많다...)

1. 문제에 동적 계획법을 사용할 수 있는지 판단
2. 상태와 매개변수를 결정
3. 상태간의 관계를 정립
4. 종료조건을 결정
5. 메모이제이션 혹은 타뷸레이션을 추가

2~4: 재귀함수 구성과 마찬가지

1: 사실 DP에서 가장 어려운 일!


## 동적 계획법을 적용 가능한 문제 판단하기

- 그냥 동적 계획법 문제를 많이 풀어볼 것
- 팁: 보통 이런 패턴
  - 어떤 제약 하에 어떤 값을 최적화(최대/최소)
    - eg. 배낭 크기(제약), 넣을 수 있는 아이템 가치 최대
  - 재귀 함수에 동일한 매개변수가 반복적으로 전달되는 경우
- 팁: 그리드를 만들려 해볼 것
  - cell 안의 값이 보통 최적화하려는 값
  - 문제를 하위 문제로 어떻게 나눌지 생각할 것(각 cell이 하위 문제)
    - eg. 배낭 문제에서 칸 수가 하위 문제이기도/각 물품들이 하위 문제이기도
  - 그러면 그리드의 x/y축을 결정하는 데 도움이 될 것임

(현실적으로 자주 문제를 풀어보고 패턴으로 인식하는 수 밖에 없다...)


## 동적 계획법으로 풀 수 있는 문제들

- 최단 경로 찾기(다익스트라 알고리즘)
- 최장 공통부분 문자열
- 와일드카드 패턴 매칭
- 부분집합 합
- 레벤슈타인 거리(편집 거리)
- 연속 행렬 곱셈
- 등 다수





<br>

# 그리디하게 푸는 배낭 문제

## 그리디(greedy,탐욕)알고리즘

- 그 순간 최적(locally optimal)의 해법을 찾는 방법
  - 미래를 전혀 생각하지 않음
  - 탐욕에 눈이 멀면 이렇게 행동한다고 해서 붙은 이름
- 최종적으로 최적(globally optimal)해법이 안 나올 수도 있음
  - 그러나 충분히 괜찮은 해법인 경우가 많음
  - 빠른 의사 결정이 가능
- ***근사(approximation) 알고리즘***!


## 그리디하게 푸는 배낭 알고리즘

- 탐욕의 기준에 따라 여러 가지 방법이 가능
  1. 가장 비싼 물건부터 넣는다
  2. 제일 작은 물건부터 넣는다
  3. 단위 면적당 값어치가 가장 높은 물건부터 넣는다
    - 단위 면적당 값어치: 값어치/공간


비싼거 우선 9불, 면적 작은거 우선 10불, 단위면적당값 큰거 우선 12불






<br>

# 쪼갤 수 있는 배낭 문제

## 그리디알고리듬의장점

- 최종적으로 최적인 해법을 못 찾을 수도 있음
- 하지만 충분히 훌륭한 결정을 빨리 내릴 수 있음
  - 보통 랜덤하게 선택하는 것보다 나음
- 수백 개의 물건을 훔쳐야 한다면?
  1. 정렬 -> O(nlogn)
  2. 순서대로 훑음 -> O(n)

-> O(nlogn)


## 쪼갤 수 있는 배낭 문제

- 이전에 본 배낭 문제는 0-1 배낭 문제
  - 물건을 훔치거나 안 훔치는 것만 가능
- 문제에 따라 일부만 취할 수 있는 경우도 있음
  - 예: 케이크를 절반만 잘라 훔치기
- 이걸 쪼갤 수 있는(fractional) 배낭 문제라고 함

이 경우 그리디 알고리즘이 최적의 해법을 찾는다

eg. 배낭 문제에서 아이템을 쪼갤 수 있을시 단위면적당값 큰거 우선으로 고르면 최적






<br>

# 그리디 알고리듬을 사용할 수 있는 경우

## 그리디 알고리즘을 사용하기 적합한 경우

- 제대로 된 해법을 구하는 알고리즘의 복잡도가 너무 높은 경우
- 적당히 좋은 해법도 상관없는 경우
- 동적 계획법을 사용할 수 없는 경우
  - 즉, 중복되는 하위 문제가 없음

## 그리디 알고리듬을 사용할 수 있는 경우

1. 최적 부분구조
2. 그리디 선택 속성: 한 번 내린 결정은 다시 돌아보지 않음
  - 과거의 선택: 현재 선택에 영향을 미칠 수 있음
  - 미래의 선택: 현재 선택에 영향을 안 미침
- 몇 가지 팁
  - 보통 최소/최대화 문제
  - 여러 그리디 선택이 가능하면 모두 시도 혹은 반례를 통해 제거할 것
  - 정렬을 해야 속도가 빨라질 수도 있음

## 그리디 접근법으로 풀 수 있는 문제

- 인터벌 파티셔닝(interval partitioning)
- 지연 시간 최소화(minimizing lateness)
- 다익스트라의 최단경로(Dijikstra's shortest path)
- 운영체제의 job 스케줄링
- k-센터 문제(k-center problem)
- 결정 트리 학습법(decision tree learning)
- 허프만 코딩(Huffman coding)
- 외 다수







<br>

# 압축 알고리듬의 큰 두 부류

## 데이터 압축

- 원본 데이터보다 적은 비트 수로 정보를 표현하는 방법
- 주 용도
  - 저장공간 절약
  - 전송속도 단축

(압축에 대해 학습은 당장은...알고리즘과 직접 관련 없으므로 생략)




<br>

# 문자열 전송과 비트 수

## 문자열 전송하기

`banana*bab`

네트워크에서 전송할 문자열(총 10글자)

- 위와 같은 문자열을 전송하려 함
- 위 문자열을 이진수로 표현해야 함
- ASCII로 인코딩하면 1글자 당 8비트
  - 문자열이 길어지면 순식간에 데이터가 커짐
  - 네트워크 속도는 상대적으로 매우 느림

(eg. 브리태니카 백과사전 총 300M자 * 8 = 2.4GB)

## 팔레트를 사용한 압축

b -> 00, a -> 01, n -> 10, * -> 11

2비트 * 10자 = 총 20비트! 1/4로 줄였다

앞의 0을 빼면?

b -> 0, a -> 1, n -> 10, * -> 11

디코딩은...?






<br>

# 허프만 코딩(Huffman coding)

문제점: 이전 팔레트에서 a의 코드(1)가 n(10)과 * (11)의 접두어!

- 입력 문자들에 적합한 가변 부호(code)를 선택하는 알고리즘
- 최적 접두어 코드(optimal prefix code)를 사용
  - 헷갈리지 않고 각 코드를 제대로 된 문자로 디코딩 가능
  - 어떤 문자에 할당된 코드는 다른 문자에 할당된 코드의 접두어가 아님


## 허프만 코딩은 그리디!

- 문자마다 사용하는 코드의 비트 수가 다를 수 있음
- 비트 수를 최소화시키는 방법은?

옵션1: 자주 등장 문자의 비트 수 많이, 가끔 등장 문자의 비트수 조금

옵션2: 자주 등장 문자의 비트 수 조금, 가끔 등장 문자의 비트수 많이

허프만 트리 사용!



## 허프만 트리(Huffman tree)

- 이진트리
- 문자는 리프 노드에 위치
- 빈도가 높은 문자일수록 루트에 가까움
- 루트부터 리프까지의 경로가 그 문자의 비트 패턴
  - 0: 왼쪽 자식으로 향함
  - 1: 오른쪽 자식으로 향함


