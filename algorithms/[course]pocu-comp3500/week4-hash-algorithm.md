# 해시 알고리즘

# 해시 알고리즘의 정의

## 다양한 해시 알고리즘의 용도

- 해시(hash)는 컴퓨터 공학에서 매우 근본이 되는 알고리듬 중 하나
- 이미 여러 번 본 해시 알고리듬의 용도
  - 해시 테이블에서 데이터를 저장할 위치를 찾기 위해
  - 길이가 긴 데이터 둘을 빨리 비교하기 위해
    - 단, 다른 경우만 빨리 비교 가능
  - 누출되면 곤란한 데이터의 원본을 저장하지 않기 위해
- 용도에 따라 해시 알고리듬의 요구사항이 조금씩 달라질 수 있음

## 해시 함수의 정의

- 임의의 크기를 가진 값을 고정 크기의 값에 대응시키는 함수
- 여전히 함수이므로 수학에서의 함수의 정의도 만족해야 함
  - 입력:출력에 있어 일대일, 다대일은 허용되나 일대다는 허용되지 않음
- 입력값이 같으면 언제나 출력값도 같아야 함(결정론적 작동)

입력 -> 해시 함수 -> 출력(32비트 정수/8비트 정수 등등...해시값, 해시코드, 다이제스트 등으로도 부른다)

이게 사실 해시 함수의 모든 필수요건이다.

다른 요건도 있지 않나? 원본 값을 찾을 수 없다던가...충돌이 적어야한다 등...이라고 할 수 있지만, 그건 해시함수의 필수 요건이 아니라, 해시 함수의 속성 중에 하나이고 어떤 속성이 어느 정도 필요한지, 그 속성이 강하게 필요할지 약하게 필요할지...등 그건 해당 해시함수를 어디에 사용할 것인지에 따라 결정되는 것이다. 즉, 용도에 따라 달라지는 속성 이라고 보는 것이 맞다. 필수 요건이 아니다.












<br>

# 해시 알고리즘의 분류와 속성

## 해시 알고리즘 분류

- (비암호학적)해시 함수
- 암호학적 해시 함수

- 체크섬(검사합, checksum)
- 순환 중복 검사(cyclic redundancy check, CRC)

이 모두 해시 함수의 필수요건을 충족! (1. 임의 크기 -> 고정크기. 2. 결정론적 작동.)

하지만 해시 알고리즘의 다른 속성은 조금씩 달라짐.



## 모든 해시 알고리즘의 속성

- 효율성(efficiency)
- 균일성(uniformity)
- 등











<br>

# 균일성

## 균일성

- 해시 함수의 출력값이 고르게 분포될수록 균일성이 높음
  - 입력값으로 기대하는 값에 대해(예: 모든 정수값, 사전에 있는 단어)
- 흔히 훌륭한 해시 함수는 균일성이 높아야 한다고 함
  - 즉, 출력 범위 안의 모든 값들이 동일한 확률로 나와야 함(균등 분포)
  - 이러면 해시 충돌이 적어 O(1) 해시 테이블을 기대할 수 있음
- 완벽한(perfect) 해시 함수: 해시 충돌이 전혀 없는 함수
  - 입력값이 매우 제한적일 경우에만 가능
  - 이유: 나중에 생일 문제(birthday problem)에서 설명


## 균일성의 측정

- 카이제곱 검정(chi-squared test)을 이용
  - n: 키(key)의 수
  - m: 버킷(bucket) 수
  - b_j: j 버킷에 들어있는 아이템 수
- 결과가 0.95 ~ 1.05 사이면 균일한 분포를 가진 해시 함수라 봄

이걸 안다고 균일성은 높일 수는 없고, 이 검정이 실무에서 잘 사용되지도 않는다.

균일성을 높일 수 있는 실용적 방법 둘이 있다.

- 해시값이 덜 중복되게 버킷 수를 정할 것(소수(나머지 연산 등을 하기 때문에 중복되는 공배수가 없으면 좋다)를 사용)
- 완벽한 '눈사태'가 나도록 해시 함수 설계할 것

## 눈사태 효과(avalanche effect)

- 입력값이 약간만 바뀌어도 출력값이 굉장히 많이 바뀌는 것
  - 보통 암호학적 알고리즘이 매우 선호하는 효과
  - 알고리즘의 규칙을 쉽게 유추할 수 없음
- 엄격한 눈사태 기준(strict avalanche criterion, SAC)
  - 입력값에서 1비트를 뒤집으면 출력값의 각 비트가 뒤집힐 확률이 50%
  - 이 기준을 충족하는 해시 함수는 분포가 균일할 가능성이 매우 높음










<br>

# 지역 민감 해시

근데 균일성은 언제나 높아야 좋은 거 아닌가? -> 안 그런 경우도 있다.

## 지역 민감 해시(locality-sensitive hashing)

- 해시 충돌의 최소화 대신 최대화를 목표로 하는 알고리즘
- 비슷한 내용을 가진 데이터끼리 충돌해야 함

왜 이런 걸 원하는지?

- 엄청나게 많은 데이터에서 비슷한 것들을 찾는 용도
  - 스팸 메일 찾기
  - 웹 검색 엔진에서 비슷한 문서 추천하기
  - 음원, 사진 등의 저작권 침해 검사
  - 등












<br>

# 효율성

## 효율성

- 보통 빠른 해시 함수를 선호함
- 공간을 더 낭비해도 빠른 접근 속도를 선호
  - 저장된 데이터를 빨리 찾는 용도로 사용하는 해시 함수
- 충돌이 좀 더 나더라도 더 빠른 함수를 선호
  - 어차피 해시 충돌은 드문 일
  - 몇 개 난다고 O(1)에서 크게 느려지지 않음
- 하지만 하드웨어 가속이 어려운 해시를 선호하는 경우도 있음
  - 여전히 소프트웨어에서는 빨리 실행되는 걸 선호
  - 뒤에 암호학적 해시 알고리듬에서 설명할 것임


## 암호학적 해시 알고리즘의 추가 속성

- 역상 저항성(pre-image resistance)
- 제 2 역상 저항성(second re-image resistance)
- 충돌 저항성(collision resistence)











<br>

# 비암호학적 해시 함수

## (비암호학적)해시 함수

- 암호학적으로 사용하기에 안전하지 않은 해시 함수들
- 보안적으로 문제 없는 용도에 주로 사용(보안적인 함수들보다 당연히 속도도 빠르다)
  - 데이터 저장 및 찾기(예: 해시테이블)
  - 저장/전송 중에 생긴 데이터 오류 탐지
  - 고유한 ID 생성
  - 등
- 이미 이 해시 함수의 작동원리에 대해서는 잘 알고 있어야 함

## 절대 반지는 없다!

- 모든 데이터에 대해 최고의 결과를 보장하는 해시 함수는 존재하지 않음
- 입력값에 따라 다른 해시 함수를 사용하는 확률적 알고리듬은 존재
  - 유니버설 해싱(universal hashing). 충돌이 적다.
- 따라서 용도에 맞는 해시 함수를 사용하는 게 중요
  - Java에서 hashCode() 구현을 각 클래스에 맡긴 이유
- 심지어는 비트 패킹(bit-packing)도 해시 함수로 사용 가능
  - 단, 균일성이 높지 않을 수는 있음


## (supplementary)비트 패킹

영상 참고.










<br>

# 올바른 해시 함수를 고르는 법

## 해시 함수를 발명하는 경우는 흔치 않음

- 제한된 데이터를 사용하는 경우 정도만 직접 발명
- 그 외의 경우에는 보통 이미 존재하는 해시 알고리듬을 사용
  - 누군가가 피와 땀을 흘려 만들고 측정한 함수
  - 그 외 많은 사람들이 사용하며 검증한 함수
  - 보통 내가 사용하는 데이터는 아주 특별하지 않음
- 우리가 집중해야 할 부분
  - 어떤 연산들이 좋은 해시 함수들을 만드는가?
  - 어디에 어떤 해시 함수를 사용해야 하는가?

## 올바른 해시 함수를 고르는 법

1. 실제로 가지고 있는 데이터로 테스트하면서 측정을 한다
  - 속도
  - 해시 충돌 수
  - 메모리(보통 크게 중요하지 않음)
  - 균일성 측정(실무에서는 잘 안 함)
2. 구글링
  - 내 데이터들이 일반적인 데이터의 경우











<br>

# Lose Lose 해시

https://softwareengineering.stackexchange.com/questions/49550/which-hashing-algorithm-is-best-for-uniqueness-and-speed

- 어떤 사람이 해시 함수를 테스트함
- 테스트에 사용한 키들
  1. 소문자 영어단어 216,553개
  2. 정수(1~216,553)
  3. 무작위로 뽑은 216,543개의 GUID


## Lose Lose 해시 함수

```C#
public uint LoseLose(byte[] str)
{
    uint hash = 0;
    foreach (byte c in str) // byte -> 8비트 ASCII캐릭터(0~255). Java의 char는 2바이트.
    {
        hash += c;
    }

    return hash;
}
```

- 프로그래밍 책에서 간단히 소개하려고 만든 코드
- 위 코드는 C#
  - 대부분의 해시 함수는 부호 없는 정수형을 사용
  - Java만 부호 없는 정수형이 없음(...)
  - Java로 구현하려면 쓸데없는 짓을 해야 함
- 매우 간단하지만 충돌이 많음









<br>

# Murmur, FNV-1 해시

## Murmur 해시 함수

bit shift, XOR 연산, 큰 값 더하기, 큰 값 곱하기 반복

## FNV-1 해시

반복문에서 큰 소수 곱하기(오버플로우 유발), XOR 연산 1회씩

(이 두 가지의 간단한 연산만으로 했는데 Murmur보다 훨씬 빠르고 훌륭한 함수가 나옴)

## FNV-1 해시

FNV-1와 모두 동일하나 큰 소수 곱하기(오버플로우 유발), XOR 연산의 순서가 바뀜. 

이것만으로도 성능과 효용이 달라짐.

(XOR은 컴퓨터에서 가장 빠른 연산 중 하나이다)







<br>

# 체크섬

## 체크섬(checksum)

- 여러 데이터로부터 도출한 작은 크기의 데이터 하나
  - 보통 데이터에 있는 모든 바이트를 어떤 방식으로든 합함
- 해시 함수랑 매우 비슷한 개념
  - 출력값의 크기가 고정되어 있으면 해시 함수

입력 -> 체크섬 -> 출력(일정한 크기)

- 용도: 저장 혹은 전송 중에 발생한 오류를 찾아냄
  - 처음 데이터를 저장할 때 체크섬을 계산해 그것도 저장
  - 나중에 데이터를 읽을 때 다시 체크섬을 계산
  - 처음에 저장해둔 체크섬과 다르면 오류가 난 것







<br>

# 체크섬의 사용례

## 주민등록 번호 유효성 검사

- 존재할 수 있는 번호인지 검사
  - 실제 존재 여부가 아님
  - 본인 인증도 아님
- 마지막 숫자는 다음 공식에 따라 계산
  - 11 -(([2,3,4,5,6,7,8,9,2,3,4,5]•[앞 12자리1) % 11)
  - 결과가 10이면 0으로 표기, 11이면 1로 표기

## 신용카드 번호의 유효성 검사
- 총 16자리
- 마지막 숫자를 룬(Luhn) 알고리즘으로 만듬

## ISBN의 유효성 검사
- ISBN 10(국제 표준 도서 번호)
  - 각 도서에 붙는 고유한 번호(총 10자리)
  - 역시 마지막 숫자가 체크섬
  - ([10,9,8,7,6,5,4,3,2,1]•[앞 9자리,x])%11==0이 돼야 함
  - x값이 10이면 X로 표기
  - ISBN 13도 비슷한 규칙이 있음






<br>

# 체크섬이 보장하는 것

## 체크섬 알고리즘은 매우 간단

- 보통 간단한 산술 연산
- 계산이 빠르고 추가 메모리가 거의 불필요
  - 네트워크 프로토콜에서 사용
  - 하드웨어로도 구현하기 쉬움
- 단, 모든 오류를 찾지는 못함
  - xor8은 'AB'와 'BA'의 체크섬이 같음
  - 위치까지 고려한 다른 알고리즘도 존재(예: Adler-32, CRC)

## 체크섬은 데이터가 바뀐지만 확인

- 보통 복구는 신경 쓰지 않음
- 따라서 체크섬이 일치하지 않으면?
  - 데이터 전송의 경우라면 재전송 요청
  - 저장 중인 데이터라면? 바이바이...
- 데이터 복구를 지원하는 것도 있음
  - 오류 정정 코드(error-correcting code, ECC) 등
  - 보통 어느 정도까지만 복구 가능

## 체크섬과 미러 사이트

- 웹사이트에서 유용한 프로그램을 배포할 경우 미러를 사용하기도 함
  - 유용한 프로그램이라 매우 많은 사람들이 다운로드
  - 한 웹사이트에서 트래픽 감당이 안 됨
  - 다른 웹사이트에서 대신 파일을 호스팅
- 그런데 미러 사이트에서 내 프로그램에 스파이웨어를 넣으면?
  - 그걸 알아낼 수 있도록 내 웹사이트에 체크섬 값을 공개해 놓음
  - 사용자는 미러 사이트에서 받은 파일에 체크섬 알고리즘을 돌림
  - 그 둘이 일치하지 않으면 누군가 변조한 프로그램
- 주의: 미러 사이트에 공개해 놓은 체크섬 값과 비교하는 건 도움 안 됨






<br>

# 패리티 비트

## 패리티 비트(parity bit)

- 이진수로 저장된 데이터에 추가하는 1비트짜리 체크섬
- 보통 1바이트 단위로 많이 사용(7비트 데이터 + 1비트 패리티)
- 짝수 패리티와 홀수 패리티로 나뉨
  - 패리티까지 포함한 모든 비트를 더하면 그 결과가 짝수 또는 홀수가 되어야 함










<br>

# 순환 중복 검사(CRC)

## 순환 중복 검사(cyclic redundancy check)

- 체크섬 알고리즘 중 하나
- 다항식의 나머지 연산을 이용하여 검사값을 만듬
  - 검사값은 보통 고정된 길이
  - 따라서 CRC 함수를 해시 함수로 사용하기도 함
- 역시 이진수 하드웨어에서 구현하기 쉬움
  - 심지어 최신 CPU는 CRC-32C 명령어를 탑재!

## CRC의 다항식과 이름

- 다항식의 최고차항에 따라 CRC에 사용하는 비트 수가 달라짐
  - 각 항의 계수는 1 아니면 0
  - 최고차항의 계수는 언제나 1
- 다음 다항식을 이진수로 표현하면? x^3 + x + 1
  - 1011 (총 4비트) -> 줄이면(최고차항 1이란 사실은 정해져있으므로) -> 011(총 3비트)
  - 이건 CRC-3-GSM에 사용하는 다항식










<br>

# CRC 계산법

## CRC-3-GSM 검증법

(과정은 영상 참고..)

eg.

10101001011001 000 <-(다항식 비트 수 -1)만큼 0 추가

1011 <-CRC다항식(x^3 + x + 1)

XOR 연산 <-원본메시지 비트가 모두 0이 될때까지

결과에서 처음의 000이 바뀐 값이 검사값이 된다.



- 결과가 0이면 오류가 없음!
  - XOR의 성질을 잘 이용한 계산법
  - 1010 ^ 1010의 결과는?

## 흔히 사용하는 CRC 알고리즘들

- CRC-8
- CRC-16
- CRC-32
- CRC-64
- 각 알고리즘에 사용하는 다항식은 위키피디아에 잘 나와있으니 참고






<br>

# 암호학적 해시 알고리즘

## 암호학적 해시 알고리즘

- 해시값에서 원본 값을 찾는 게 사실상 실행 불가능한 알고리즘
  - 일방향 함수(one-way function)
  - 수학적인 지식이 많이 요구되는 부분
  - 따라서 이미 있는 해시 함수를 주로 사용
- 원본 값을 찾으려면 모든 조합을 모두 시도해봐야 함(무차별 대입 공격)
  - 이상적 목표
  - 암호학적 해시 함수로 분류된 것 중 이미 깨진 것들이 있음(...)
- 보안 분야에서 다양한 용도로 사용

## 암호학적 해시 알고리즘 용도 예

- 메시지나 파일의 무결성(integrity) 검사
  - 예: 앞에서 든 미러 사이트에서 파일 다운로드하기
- 디지털 서명 생성 및 검증
- 비밀번호 검증
- 작업 증명(proof-of-work, PoW)
  - 블록체인 등에서 서비스 거부 공격(DoS)을 어렵게 만들기 위해
- 일반 해시 알고리듬 대신으로 사용 가능(단, 더 느리다)


## 암호학적 해시 알고리즘의 예

HAVAL, MD4, MD5, RIPEMD, RIPEMD-160, SHA-1, SHA-256/224, SHA-512/384, Tiger(2)-192/160/128, WHIRLPOOL

MD5(출력 비트수 128), SHA-1(160)이 간단하고 빨라 굉장히 많이 사용되나, 더이상 안전하지 않아 사용하지 말라는 권고가 나왔다.






<br>

# 암호학적 해시 알고리즘의 추가 속성

## 암호학적 해시 알고리즘의 추가 속성

- 역상 저항성(pre-image resistence)
- 제 2 역상 저항성(second pre-image resistence)
- 충돌 저항성(collision resistence)

이것들이 높을 수록 암호학적으로 사용하기에 올바른 것. 낮다면 어떤 공격에 취약하다는 뜻.


## 역상 저항성(pre-image resistence)

- 해시값으로부터 원본 데이터를 찾기가 어려워야 함
  - 즉, 원본 데이터를 같이 저장하지 않는 용도에 적합
  - 예: 비밀번호 저장
- 비보안학적 해시 함수에서 본 비트 패킹은 역상 저항성이 거의 없음
  - 낮은 역상 저항성을 이용하는 게 역상 공격(pre-image attack)
  - 무차별 대입 공격을 통해서만 해시값을 찾을 수 있는 것이 이상적!
- 즉, 해시값으로부터 패턴을 보기 어려워야 함
  - 좋은 알고리듬의 필요성(예: 산사태 효과)
  - 해시값의 길이가 길수록 좋음


## 제 2 역상 저항성(second pre-image resistence)

- 똑같은 해시값이 나오는 다른 입력값을 찾기 어려워야 함
  - (입력값, 해시값)쌍을 이미 가지고 있을 때
  - 이 저항성이 낮으면 제 2 역상 공격에 취약
- 역상 저항성보다 한 가지 정보가 더 있는 경우
  - 역상 저항성은 해시값만 있음
  - 제 2 역상 저항성은 입력값도 알고 있음


## 충돌 저항성(collision resistence)

- 해시값이 똑같은 두 입력값을 찾기가 어려워야 함
  - 해시값도 입력값도 주어지지 않은 경우
  - 이 저항성이 낮으면 충돌 공격에 취약
- 충돌 공격은 역상 공격들 보다 쉬움
  - 이미 MD5와 SHA-1에 대해 실행 가능한 충돌 공격이 발견됨
  - MD5는 일반 컴퓨터로 몇 초면 충분할 정도 (...)
  - 모든 암호학적 해시 함수는 생일 공격(birthday attack)이 가능하기 때문
  - 생일 공격은 무차별 대입 공격보다 빠름 (이유: 생일 문제)





<br>

# 생일 문제(birthday problem)

- 회사 직원 수는 20명
- 이 중에 생일이 9월 1일인 직원이 있을 확률은?
  - 1 - (364/365)^20 = 5.3%
  - (역상 공격과 비슷...9월 1일이라는 데이터가 주어져있음)
- 그날 생일이 겹치는 사람이 있을 확률은?
  - 겹치지 않는 총 경우의 수: P(365,20) = 365!/(365-20)!
  - 겹칠 확률: 1 - 365! / ((365-20)! * 365^20) = 41.1%
  - (충돌 공격과 비슷...주어진 데이터가 없을 경우)

## 생일 문제를 해결(?)하는 법

1 - 365! / ((365-20)! * 365^20) = 41.1%

- 출력값의 길이가 정해져 있기에 생기는 문제
  - 모든 암호학적 해시 함수가 생일 공격에 노출되어 있는 경우

위 공식에서 출력값의 길이는? -> 365

- 출력값의 길이를 늘리면 그 확률을 줄일 수 있음
  - 해시값의 크기가 클수록 좋은 이유

1 - 3650! / ((3650-20)! * 3650^20) = 5.1%







<br>

# 보안 이야기: 비밀번호 터는 법

## 비밀번호를 해시로 저장해야 하는 이유

- 웹사이트에서 모든 조합의 비밀번호를 시도하는 건 보호하지 않음
  - 해시값을 몰라도 DB와 비교해서 로그인 해주기 때문
  - 무차별 대입 공격은 여러 제약이 있음
    - 웹페이지 갱신 속도
    - 5번 실패후 계정 잠금 등
- 데이터베이스가 털렸을 때 비밀번호가 노출되는 걸 막음
  - 사람들은 같은 비밀번호를 여러 사이트에 사용
  - 여기서 털은 걸 다른 사이트에서 사용하면 됨
  - 각 사이트마다 다른 비밀번호를 사용해야 하는 이유

## 해시에서 비밀번호를 찾는 법

1. 해커의 컴퓨터에서 모든 조합의 비밀번호를 시도(무차별 대입 공격)

- 웹에서 시도할 때의 제약을 받지 않음
- 하드웨어 가속도 가능
  - 저가 그래픽 카드 하나로 초당 100억 개 이상의 MD-5를 계산할 수 있음
  - 영어 대소문자 8자리로 만들 수 있는 비밀번호는 약 534597억 개
  - 전부 시도하는데 걸리는 시간 1.5시간 미만 (...)
- 하드웨어서만 효율성이 떨어지는 알고리듬을 선호
- 비밀번호는 길수록 좋음(길이에 따라 경우의 수 기하급수적 증가)

2. 해커의 컴퓨터에서 사전에 있는 단어들로 시도(사전 공격)

- 무차별 대입 공격과 기본은 같음
- 하지만 사전에 있는 단어들을 조합해가며 시도
  - 사람들은 보통 기억하기 쉬운 단어를 비밀번호로 사용
  - 무차별 대입 공격보다 빠름
- 비밀번호 생성기에서 생성한 뷁스러운 비밀번호가 더 나은 이유

3. 해커가 가지고 있는 레인보우 테이블과 비교

- 레인보우 테이블: 미리 계산해 놓은 해시값의 목록
  - 흔히 사용하는 비밀번호들을 모두 계산한 결과를 저장
  - 흔히 사용하는 모든 해시 함수에 대해
  - 매우 싼 가격에 살 수 있음 (...)
- 레인보우 테이블과 일치하는 해시값이 저장되어 있다면 찾는 시간은?
  - 해시 테이블과 같음
  - 0(1)

1~3번 모두 알려져 있는 해시 함수를 사용해서 생기는 문제. 하지만 나만의 해시함수를 만드는 건 매우 나쁜 생각.

## 독자적인 해시 함수 사용이 안 좋은 이유

- 보안업계에서 독자적인 암호학적 해시함수 사용을 비추
  - 어떤 취약점이 있는지 알 수 없음
  - 보안감사를 제대로 하지 않음
  - 따라서 전문가들은 자체 암호화 기법을 사용하는 서비스를 피함
- 공개적으로 검증된 해시 함수를 주로 사용
  - 초천재 수학자들과 보안전문가들이 개발 및 감사를 한 것들
  - 막강한 정부의 자금과 인력도 투입(예: 미국 국립표준기술연구소, NIST)
  - 취약점이 발견되면 다 같이 털린다는 문제가 있음
  - 정부에 대한 음모론도 존재(...)









<br>

# 보안 이야기: 비밀번호 덜 털리는 법

## 비밀번호 덜 털리는 법(사용자 교육편)

1. 이미 털렸다고 알려진 비밀번호를 설정 못하게 한다
  - 대규모로 털린 비밀번호 목록을 웹에서 찾을 수 있음(API도 존재)
  - 그 비밀번호를 입력하면 다른 비밀번호를 만들라고 강제
2. 긴 비밀번호를 사용하게 강제한다
  - 비밀번호의 자릿수가 늘어나면 시도해야 할 조합이 기하급수적으로 증가
3. 아예 비밀번호를 저장하지 않는다(보안 기본: 필요하지 않은 정보는 되도록 저장하지 않는다)
  - 이메일로 보낸 링크를 클릭하면 로그인이 되는 방법
  - 소셜 로그인만 받는 방법

## 비밀번호 덜 털리는 법(기술편)

1. 소금(salt)를 뿌린다
  - 비밀번호 처음 저장시 랜덤 문자열(salt)도 같이 저장
  - 더 이상 레인보우 테이블에서 찾을 수 없음
  - 각 비밀번호마다 무차별 대입 공격 및 사전 공격을 해야 함
2. 후추(pepper)도 친다
  - 모든 비밀번호에 붙이는 ***공통***된 문자열
  - 데이터베이스에 저장하지 않고 웹 서버(메모리)에서만 알고 있는 값
    - 해커가 가지고 있지 않기에 거의 모든 공격을 무력화
    - 단, 데이터베이스 털릴 때, 웹 서버 메모리까지 털리면 도루묵(...)

## 소금 vs 후추

|소금|후추|
|---|---|
|흰색(눈에 잘 띔)|검은색(눈에 잘 안띔)|
|해커에게 보임|해커에게 안 보임|
|레인보우 테이블 무력화|레인보우 테이블 무력화|
|비밀번호마다 공격을 반복하게 만듬|사전 공격 무력화|
|-|비밀번호의 길이를 늘리는 효과|

## 마지막 조언

- 업계에서 최고의 해시 함수라고 말하는 것을 선택할 것
- 보안 관련 뉴스를 구독할 것
  - 해시 함수는 언제든 깨질 수 있음
  - 그러면 재빨리 더 나은 함수로 바꿔야 함
  - 해시 함수가 바뀌니 비밀번호를 다 리셋해야 함
- 비밀번호 찾기를 허용하는 웹사이트를 조심할 것
  - 리셋이 아닌 찾기를 허용한다면 내 비밀번호가 저장되어 있다는 말(...) -> 해당 사이트는 보안을 위해 탈퇴하거나, 거기서만 쓰는 비밀번호 사용하는 편이 낫다.









