[01.v.02] 본문

—
데이터

237.8 million monetizable daily active users (mDAU). <2022기준, 1>

345k / 4.6k * 6k = 450k <2022기준, 2, 3>
타임라인: 초당 45만 읽기 요청
읽기: 초당 450k 읽기
쓰기: 초당 6k 쓰기
읽기 쓰기 비율 75:1

타임라인에서 한 번에 트윗 10개를 읽어 온다고 하면 초당 4,500k 읽기 요청과 같다.
(물론 트윗 10개를 읽어올 때 한 번에 10개를 DB에서 읽는 것과, 트윗 1개씩 읽기 요청을 10번 하는 것은 다를 것이다)
(그럴 시 읽기 쓰기 비율 750:1)

(과거 RDB를 사용하는 배달의 민족 서비스의 한 프로모션 행사 역대급 트래픽에서 초당 읽기 요청이 50k 정도가 나왔다고 한다. 이보다 트위터에서는 100배 넘는 트래픽이 일상적으로 일어나고 있는 것이다.)

읽기 요청에 대한 부하가 훨씬 더 클 것이라고 예상했다. 그렇다면 어떻게 읽기 성능을 보장할 수 있을까?

이와 같은 문제를 해결하기 위해 크게 두 가지 알고리즘을 떠올려 보았다.
캐싱 안하는 이유 언급
알고리즘1

쓰기 시
    1. 트윗을 모든 트윗들이 모여있는 전역 테이블에 바로 쓴다.

읽기 시
    1. 유저를 모두 읽는다, 내가 팔로잉하는
    2. 트윗을 모두 읽는다, 내가 팔로잉하는 유저의
    3. 시간 순으로 정렬한 트윗을 벌크 로드한다.

이는 가장 기본적인 알고리즘이라고 볼 수 있다. 흔히 ‘게시판’ 등의 서비스에서 이렇게 쓰일 수 있을 것이다. pull 방식.

알고리즘2:

두 번째 생각해낸 알고리즘은 읽기를 요청 시점에 조회하는 것이 아니라, 미리 준비를 해놓을 수는 없을까?하는 아이디어에서 나왔다.

쓰기 시
    1. 각 유저별로 자신만의 타임라인 저장소를 갖고 있다.
    2. 트윗을 작성해 쓰기 요청한다.
    3. 작성자를 팔로우하는 사람들의 목록을 읽는다.
    4. 팔로우 목록의 각 타임라인 저장소에 트윗을 쓴다(fan-out).

읽기 시
    1. 미리 쌓아둔 트윗 목록을 벌크 로드 한다.

이는 마치 메일함이나 메신저와 같다고 볼 수 있다. 쓰기 시점에 여러사람에게 메일을 보내는 것과 비슷하다고 볼 수 있겠다. push 방식이라고 볼 수 있다.

어떤 것을 선택해야할까?

트위터는 초당 6천 쓰기를 하는 대용량 데이터가 발생하며, 이런 대용량 데이터의 홍수 속에서 읽기 성능을 보장하는 데에 전통적인 접근법으로는 한계가 있을 것이라고 판단했다.

다만 위에 기술한대로 SNS의 통상적인 요구사항상 쓰기보다 읽기 성능에 대한 요구가 더 크기에 알고리즘 2를 우선해 적용해야 겠다고 생각했다.

즉, 알고리즘 2는 쾌적한 사용자 경험을 위해 쓰기라는 비용을 지불해 사전에 미리 연산을 해놓는다고 볼 수 있다(pre-computing).

다만, 알고리즘 2를 위해선
* 쓰기 부하
* 중복 데이터 발생으로 인한 저장 공간
* 애플리케이션 복잡도 증가
라는 트레이드 오프가 발생하게 된다.



다만 여기에서 추가로 고민해 봐야하는 변수가 있다. 바로 팔로우 기능이다.

문제1 - 팔로워가 많은 사람의 쓰기

트위터의 대표적 셀럽 유저 일론 머스크는 1억 명 이상의 팔로워를 보유하고 있다. 알고리즘 2를 구현할 경우 일론머스크가 트윗을 할 때마다 1억 명의 타임라인에 트윗을 1개씩 총 1억 개를 써야하는 큰 부하가 발생하게 된다.

이런 상황에서도 과연 알고리즘 2를 사용하는 것이 합리적일까? 또한 시스템이 이런 큰 쓰기 부하를 견딜 수 있을까?

(SNS는 가용성 뿐만 아니라 짧은 지연 시간(latency)이 가장 중요하게 여겨지므로, 지불할 수 있는 비용이라고 생각하였다)

문제2 - 팔로잉이 많은 사람의 읽기

유저의 팔로잉 분포 범위는 팔로워 분포 범위보다 넓지 않다는 가설은 유효할 것이다. 예를 들어 일론 머스크의 팔로워는 1억명이 넘는 반면, 한 유저가 팔로잉하는 수는 대체로 100명에서 많아야 1,000명 수준일 것이다(한 유저가 1억명의 유저를 팔로우하진 않는다).

따라서 팔로잉이 많은 사람의 타임라인 읽기는 크게 고려하지 않아도 된다고 치부할 수 있지만, 그렇지 않을 수 있다. 타임라인 읽기 요청의 시간복잡도를 생각해보자. user, tweet, follow 테이블의 인덱스가 최적화 되어있다고 가정시

O(m * log(n) * log(kn))

m: 팔로잉 수
n: 전체 유저의 수
k: 유저당 평균 트윗 수

가 되는데, 단순 수식 측면에서 봤을 때 n과 k의 경우 log의 진수이다. 즉, n과 k은 로그 증가를 한다. k와 n이 아무리 커져도 결국 일정 범위 이상이 되면 로그 증가에서 상수 증가에 가까워지며 영향이 미미해진다. 반면 m의 경우 값에 비례해 선형 증가한다.

즉, 팔로잉의 수가 늘어나는 것은 타임라인 읽기 연산에 상대적으로 큰 영향을 준다.

문제 1과 문제 2를 어떻게 해결할 수 있을까?

문제 1의 해결:

팔로워 수가 특정 임계치를 넘은 유저의 쓰기에 있어 알고리즘1(pull 방식)을 우선 적용하고, 그외 모든 유저에 대해 알고리즘2(push 방식)를 적용한다.

문제 2의 해결:

팔로잉 수가 특정 임계치를 넘은 유저를 대상으로 팔로잉 목록을 미리 저장해둔다.

문제2의 해결은 알고리즘1일 때 크게 유효하다. 
문제1의 해결과 문제2의 해결은 양립하기 어렵다.

예를 들어 알고리즘2의 방식 도입시엔 쓰기 시점에 팔로잉 목록을 불러와야 하는데, 이 때 이미 작성자의 팔로워 수를 기준으로 독자들의 타임라인을 채워놓는다.

그렇다면 독자들이 읽기 요청시에 알아야할 것은 셀럽에 해당하는 유저의 목록들만 DB에 조회하면 된다.

독자의 읽기 시점에 미리 저장된 팔로잉 목록을 조회하는 것이 아니란 것이다.

쓰는 사람의 팔로워 기준
읽는 사람의 팔로잉 기준

알고리즘2-1
쓰기 시
    1. DB에 트윗을 쓴다.
    2. 본인이 비셀럽 유저에 해당하는지 확인한다.
    3. (본인이 비셀럽일시)팔로워 목록 전체를 불러온다.
    4. 트윗을 팔로워 목록의 타임라인 저장소에 쓴다.

읽기 시
    1. 미리 저장해둔 비셀럽의 트윗목록을 타임라인 저장소에서 읽는다(유저아이디 하나면 ok).
    2. 셀럽 목록을 파생 저장소에서 읽는다.
    3. 셀럽의 트윗목록을 DB에서 읽는다.
    4. 셀럽, 비셀럽 트윗목록을 병합한다.


알고리즘2-2
쓰기 시
    1. DB에 트윗을 쓴다. 
    2. 팔로워 목록 전체 중 헤비유저 목록을 추려서 불러온다.
    3. 팔로워들 중 헤비유저 목록을 추린다.
    4. 트윗을 헤비유저 목록의 타임라인 저장소에 쓴다.

읽기 시
    1. 본인이 헤비유저에 해당하는지 확인한다.
    2. (본인이 헤비유저일시)파생 저장소에서 모든 트윗을 읽어온다.


팔로잉 목록이 특정 임계치를 넘은 사람의 트윗은 미리 저장해둔다?
읽기 요청시 미리 저장해둔 팔로잉 목록을 불러와 RDB에 읽기 요청을 한다.

팔로잉 쓰기시
임계치를 확인한다
임계치를 넘으면 팔로잉 많은 사람으로 따로 분류하여 팔로잉 목록을 미리 저장해둔다.


what to choose? 알고리즘 2-1

알고리즘 2-1과 2-2는 기본적으로 비슷한 읽기와 쓰기 부하를 주도록 설계할 수 있다. 

단지 알고리즘 2-1의 경우 팔로워의 임계치를, 알고리즘 2-2의 경우 팔로잉의 임계치를 어떻게 설정하는지에 따라 읽기와 쓰기의 부하 분산이 가능해진다.

나는 2-1의 알고리즘을 선택하였는데, 이유는 
* 임계치로 설정할 값(팔로워 수)의 표본의 분포가 더 다양하기 때문에 임계치 설정에 있어 보다 세밀한 설정이 가능할 것이며, 
* 셀럽인지 비셀럽인지에 따라 fanout 쓰기 여부를 결정하는 것이 시스템 구현에 있어 보다 직관적이라고 판단하였다.

그 외 구현에 있어 세부사항으로 읽기 요청 당시 셀럽의 트윗의 경우 셀럽 유저목록을 불러와야 하는데(위에서 서술했듯 팔로잉의 수가 늘어나는 것은 타임라인 읽기 연산에 상대적으로 큰 영향을 준다), 그를 위해서 읽기 요청 당시 DB에서 셀럽 팔로잉 목록을 조회하는 연산을 줄이기 위해 팔로우중 셀럽인 유저목록도 타임라인과 같이 따로 저장해둘 수 있도록 구현하였다.


이후 구현 코드 및 시퀀스 다이어그램 삽입








——
1. https://www.statista.com/statistics/970920/monetizable-daily-active-twitter-users-worldwide/
2. https://www.dsayce.com/social-media/tweets-day/
3. 데이터 중심 애플리케이션 설계


——
링크드인 프로필 읽기 요청과 다르게 트위터의 타임라인은 실시간으로 변하기에 훨씬 더 큰 복잡성을 갖는다.








——
팔로잉의 분포 범위가 넓지 않은 상황에서 팔로잉이 많은 사람을 특정 기준으로 나누고 해당 유저에 대해 별도의 팔로잉 목록을 미리 저장해 두는 것은 오히려 불필요하게 애플리케이션 복잡도를 증가시킨다고 판단했다.

예를 들어 push 방식으로 미리 타임라인을 저장해 놓으면, 읽기 요청이 들어왔을 때 비셀럽 유저의 목록을 불러올 일이 적다.

반대로 셀럽 유저에 대해선 읽기시 셀럽 유저 목록이 필요하게 되는데, 이 목록은 미리 캐싱을 해두는 방식으로 읽기시 부하를 최소화 시킬 수 있는 것이다.

(쓰기시 비셀럽 유저의 팔로잉 목록을 미리 저장해두면 쓰기시 부하를 줄일 수 있겠지만, 우선 읽기 요청 성능에 집중하기 위해 해당 부분을 구현하진 않았다)


——
전자의 범위가 한 유저가 1억 명의 유저를 팔로우하진 않는다. 대부분의 경우, 많이 팔로우를 해봤자 수 십, 수 백 정도에 그칠 것이다. 


——
타임라인의 시간복잡도 분석

알고리즘1
팔로우를 찾는다(logF) + 트윗들을 찾는다(logT)

알고리즘2

그보단 알고리즘 2의 경우 팔로워의 분포와 더 큰 관련이 있다.


———
추론

변수가 있다.

팔로우의 분포이다.

문제: 팔로우 수의 분포는 1억 명까지 분포가 매우 다양하다. (일론머스크의 팔로워는 1억5천만 명이 넘는다)

1억 6천만 명 팔로워 보유 셀럽의 트윗 읽기 요청 집중을 어떻게 감당할까?

